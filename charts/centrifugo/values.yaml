# ============================================
# GLOBAL PARAMETERS
# ============================================
# Global values can override chart-specific settings.
# Useful when this chart is used as a sub-chart in an umbrella chart,
# or when you want to apply the same settings across multiple charts.
#
# Supported global parameters:
# - imageRegistry: Override image.registry for all images
# - imagePullSecrets: Override imagePullSecrets for all images
#
# global:
#   imageRegistry: my-private-registry.com
#   imagePullSecrets:
#     - my-registry-secret

replicaCount: 1

# Number of old ReplicaSets to retain for rollback
revisionHistoryLimit: 10

image:
  registry: docker.io
  repository: centrifugo/centrifugo
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []

nameOverride: ""
fullnameOverride: ""
# Namespace is installation concern, not chart concern, namespaceOverride is not recommended to be used.
namespaceOverride: ""
priorityClassName: ""

# Annotations to be added to the deployment
annotations: {}

# ============================================
# CENTRIFUGO SERVERS
# ============================================
# Configuration for Centrifugo servers.
# These define what ports Centrifugo listens on inside the container.
# Service ports (configured below) can be different and will forward to these ports.
servers:
  # External server for client connections (WebSocket, HTTP streaming/SSE with emulation,
  # unidirectional HTTP transports)
  external:
    port: 8000
  # Internal server endpoints (server HTTP API, health checks, Prometheus metrics, admin UI)
  internal:
    port: 9000
    # Scheme for HTTP/HTTPS (used by probes and metrics scraping)
    scheme: HTTP
  # GRPC API server for backend operations (publish, presence, history, etc.)
  grpc:
    port: 10000
  # Unidirectional GRPC server for streaming
  uniGrpc:
    port: 11000

# ============================================
# SERVICE CONFIGURATION
# ============================================

## Main service configuration.
## By default, this service exposes all servers (external, internal, grpc, uni-grpc).
## Use serviceInternal.useSeparate, serviceGrpc.useSeparate, serviceUniGrpc.useSeparate
## to split servers into dedicated services with their own configuration.
service:
  ## Service type
  ##
  type: ClusterIP
  ## Service port (external-facing port number)
  ## This forwards to servers.external.port (default: 8000)
  ## You can set this to any port (e.g., 443 for HTTPS) independent of the server port.
  port: 8000
  ## Specify the nodePort value for the LoadBalancer and NodePort service types.
  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
  ##
  nodePort: ""
  ## Specify clusterIP for the service. If not specified, Kubernetes will assign one.
  ## Set to "None" for headless service.
  clusterIP: ""
  ## Provide any additional annotations which may be required
  ##
  annotations: {}
  ## Provide any additional labels which may be required
  ##
  labels: {}
  ##
  ## Specify custom appProtocol for a service port.
  appProtocol: ""

## Internal service configuration.
## By default, internal port is exposed on the main service above.
## Use useSeparate: true to have a separate service definition.
serviceInternal:
  ## Use separate Kubernetes Service for internal endpoints.
  ## Useful for applying different Service configurations (type, annotations, labels),
  ## network policy isolation, or separate LoadBalancer IPs per endpoint type.
  useSeparate: false
  ## Service port (forwards to servers.internal.port, default: 9000)
  ## Used in both modes: on main service when useSeparate=false, on separate service when useSeparate=true.
  port: 9000
  ## Static NodePort for this port. When useSeparate=false, only used if main service.type is NodePort/LoadBalancer.
  nodePort: ""
  ## Service type. Only used when useSeparate=true to set the separate service type.
  type: ClusterIP
  ## Specify clusterIP for the service. If not specified, Kubernetes will assign one.
  ## Only used when useSeparate=true (separate service).
  clusterIP: ""
  ## Custom appProtocol for this port. Used in both modes.
  appProtocol: ""
  ## Service annotations. Only used when useSeparate=true (separate service).
  annotations: {}
  ## Service labels. Only used when useSeparate=true (separate service).
  labels: {}

## GRPC API service configuration.
## By default, GRPC API port is exposed on the main service above.
## Use useSeparate: true to have a separate service definition.
serviceGrpc:
  ## Use separate Kubernetes Service for GRPC API endpoints.
  ## Useful for applying different Service configurations (type, annotations, labels),
  ## network policy isolation, or separate LoadBalancer IPs per endpoint type.
  useSeparate: false
  ## Service port (forwards to servers.grpc.port, default: 10000)
  ## Used in both modes: on main service when useSeparate=false, on separate service when useSeparate=true.
  port: 10000
  ## Static NodePort for this port. When useSeparate=false, only used if main service.type is NodePort/LoadBalancer.
  nodePort: ""
  ## Service type. Only used when useSeparate=true to set the separate service type.
  type: ClusterIP
  ## Specify clusterIP for the service. If not specified, Kubernetes will assign one.
  ## Only used when useSeparate=true (separate service).
  clusterIP: ""
  ## Custom appProtocol for this port. Used in both modes.
  appProtocol: ""
  ## Service annotations. Only used when useSeparate=true (separate service).
  annotations: {}
  ## Service labels. Only used when useSeparate=true (separate service).
  labels: {}

## Unidirectional GRPC service configuration.
## By default, uni GRPC port is exposed on the main service above.
## Use useSeparate: true to have a separate service definition.
serviceUniGrpc:
  ## Use separate Kubernetes Service for GRPC unidirectional stream.
  ## Useful for applying different Service configurations (type, annotations, labels),
  ## network policy isolation, or separate LoadBalancer IPs per endpoint type.
  useSeparate: false
  ## Service port (forwards to servers.uniGrpc.port, default: 11000)
  ## Used in both modes: on main service when useSeparate=false, on separate service when useSeparate=true.
  port: 11000
  ## Static NodePort for this port. When useSeparate=false, only used if main service.type is NodePort/LoadBalancer.
  nodePort: ""
  ## Service type. Only used when useSeparate=true to set the separate service type.
  type: ClusterIP
  ## Specify clusterIP for the service. If not specified, Kubernetes will assign one.
  ## Only used when useSeparate=true (separate service).
  clusterIP: ""
  ## Custom appProtocol for this port. Used in both modes.
  appProtocol: ""
  ## Service annotations. Only used when useSeparate=true (separate service).
  annotations: {}
  ## Service labels. Only used when useSeparate=true (separate service).
  labels: {}

ingress:
  enabled: false

  # Optionally set the ingressClassName.
  ingressClassName: ""

  # pathType override - see: https://kubernetes.io/docs/concepts/services-networking/ingress/#path-types
  pathType: Prefix
  labels: {}
    # extrenal-dns: true
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    #
    # To run on custom path:
    # nginx.ingress.kubernetes.io/rewrite-target: /$2
  hosts: []
    # - host: centrifugo.local
    #   paths:
    #     - /
    # - host: centrifugo-with-prefix.local
    #   paths:
    #     - /test(/|$)(.*)
  # https://kubernetes.github.io/ingress-nginx/examples/tls-termination/
  tls: []
    # - secretName: centrifugo-example-tls
    #   hosts:
    #     - centrifugo.local

ingressInternal:
  # !!! ATTENTION !!!
  # Be careful in exposing internal services by ingressInternal. Make sure
  # you understand which Centrifugo endpoints are exposed in this case (server API,
  # admin, Prometheus metrics, healthcheck, etc.). If you really need exposing internal
  # endpoints consider limiting access to the ingress from the outside by load balancer
  # rules, probably per specific path. Probably `admin_external` or `api_external`
  # options which expose corresponding handlers on the external ingress will work better
  # for you.
  enabled: false

  # Optionally set the ingressClassName. k8s >= 1.18
  ingressClassName: ""

  # pathType override - see: https://kubernetes.io/docs/concepts/services-networking/ingress/#path-types
  pathType: Prefix
  labels: {}
    # external-dns: true
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    #
    # To run on custom path:
    # nginx.ingress.kubernetes.io/rewrite-target: /$2
  hosts: []
    # - host: centrifugo.local
    #   paths:
    #     - /
    # - host: centrifugo-with-prefix.local
    #   paths:
    #     - /test(/|$)(.*)
  # https://kubernetes.github.io/ingress-nginx/examples/tls-termination/
  tls: []
    # - secretName: centrifugo-example-tls
    #   hosts:
    #     - centrifugo.local

resources: {}
  # requests:
  #   cpu: 100m
  #   memory: 128Mi
  # limits:
  #   cpu: 500m
  #   memory: 256Mi

serviceAccount:
  # Specifies whether a service account should be created.
  create: true
  # Annotations to add to the service account.
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template.
  name: ""

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  cpu:
    enabled: false
    targetCPUUtilizationPercentage: 80
  memory:
    enabled: false
    targetMemoryUtilizationPercentage: 80
  # Custom HPA metrics (e.g., Prometheus metrics via prometheus-adapter)
  # ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-metrics-apis
  # ref: https://github.com/kubernetes-sigs/prometheus-adapter/
  customMetrics: []
  # - type: Pods
  #   pods:
  #     metric:
  #       # kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/*/hpa_custom_metric_centrifugo_node_num_clients" | jq .
  #       name: hpa_custom_metric_centrifugo_node_num_clients
  #     target:
  #       type: AverageValue
  #       averageValue: 10000m # NOTE: # 10000m = 10 actual metric value (10 clients)
  # Scaling behavior configuration
  # ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#default-behavior
  behavior: {}

podDisruptionBudget:
  enabled: false
  # Minimum number/percentage of pods that must remain available during disruption.
  # Cannot be used together with maxUnavailable.
  minAvailable: 1
  # Maximum number/percentage of pods that can be unavailable during disruption.
  # Cannot be used together with minAvailable.
  # maxUnavailable: 1

terminationGracePeriodSeconds: 30

# Container lifecycle hooks.
# Default: preStop sleeps for 5 seconds to avoid endpoint propagation race condition.
# Set to null to disable all lifecycle hooks: lifecycle: null
lifecycle:
  preStop:
    exec:
      command: ["/bin/sh", "-c", "sleep 5"]
# Example with postStart:
#  postStart:
#    exec:
#      command: ["/bin/sh", "-c", "echo Hello from the postStart handler"]

podAnnotations: {}
podLabels: {}

# Pod-level security context: identity and filesystem settings
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000
  # You can also tune sysctl settings (pod-level only):
  # sysctls:
  #   - name: net.core.somaxconn
  #     value: "2048"

# Container-level security context: privileges and capabilities
securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: true

deploymentStrategy: {}
  # type: RollingUpdate
  # rollingUpdate:
  #   maxSurge: 0
  #   maxUnavailable: 1

extraContainers: []
#  - name: my-sidecar
#    image: nginx:latest

# ============================================
# POD-LEVEL CONFIGURATION
# ============================================

# Host aliases for the pod.
# See https://kubernetes.io/docs/tasks/network/customize-hosts-file-for-pods/
hostAliases: []
#  - ip: "127.0.0.1"
#    hostnames:
#      - "foo.local"
#      - "bar.local"

# Runtime class for the pod (e.g., gvisor, kata-containers).
# See https://kubernetes.io/docs/concepts/containers/runtime-class/
runtimeClassName: ""
#  runtimeClassName: "gvisor"

# Share process namespace between containers in the pod.
# Useful for debugging/profiling with sidecars.
# See https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/
shareProcessNamespace: false

# Custom scheduler name.
# See https://kubernetes.io/docs/tasks/extend-kubernetes/configure-multiple-schedulers/
schedulerName: ""
#  schedulerName: "my-custom-scheduler"

# Overhead represents the resource overhead associated with running a pod.
# Used with VM-based runtimes like Kata Containers.
# Note: Beta in Kubernetes 1.18-1.23, GA in 1.24+
# See https://kubernetes.io/docs/concepts/scheduling-eviction/pod-overhead/
overhead: {}
#  cpu: "250m"
#  memory: "128Mi"

# ============================================
# CONTAINER-LEVEL CONFIGURATION
# ============================================

# Termination message policy for the container.
# Options: File (default), FallbackToLogsOnError
# See https://kubernetes.io/docs/tasks/debug/debug-application/determine-reason-pod-failure/
terminationMessagePolicy: ""
#  terminationMessagePolicy: "FallbackToLogsOnError"

# Liveness probe for the main Centrifugo container.
# Default: httpGet probe on /health endpoint using servers.internal.port and servers.internal.scheme.
# You can override with full probe configuration.
livenessProbe: {}
#  httpGet:
#    path: /health
#    port: 9000  # Should match servers.internal.port
#    scheme: HTTP  # Should match servers.internal.scheme (HTTP or HTTPS)
#  initialDelaySeconds: 30
#  periodSeconds: 10
#  timeoutSeconds: 1
#  successThreshold: 1
#  failureThreshold: 3

# Readiness probe for the main Centrifugo container.
# Default: httpGet probe on /health endpoint using servers.internal.port and servers.internal.scheme.
# You can override with full probe configuration.
readinessProbe: {}
#  httpGet:
#    path: /health
#    port: 9000  # Should match servers.internal.port
#    scheme: HTTP  # Should match servers.internal.scheme (HTTP or HTTPS)
#  initialDelaySeconds: 3
#  periodSeconds: 10
#  timeoutSeconds: 1
#  successThreshold: 1
#  failureThreshold: 3

# Startup probe for the main Centrifugo container.
# Useful for slow-starting containers to avoid liveness probe killing the pod.
# See https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
startupProbe: {}
#  httpGet:
#    path: /health
#    port: 9000
#  failureThreshold: 30
#  periodSeconds: 10

## Prometheus metrics configuration.
## Note: Prometheus metrics endpoint (/metrics) is always enabled on the internal port.
## This section configures the ServiceMonitor for Prometheus Operator.
##
## DISTRIBUTED SETUPS (Multiple Replicas):
## When running Centrifugo with multiple replicas, the ServiceMonitor automatically discovers
## and scrapes each pod individually. Prometheus will create separate scrape targets for each
## replica, ensuring you get metrics from all nodes in your distributed deployment.
##
## Example for multi-replica setup:
##   replicaCount: 3
##   metrics:
##     serviceMonitor:
##       enabled: true
##       interval: 30s
##       additionalLabels:
##         release: prometheus  # Match your Prometheus Operator's serviceMonitorSelector
##
## This will result in Prometheus scraping all 3 pods individually at http://<pod-ip>:9000/metrics
##
metrics:
  serviceMonitor:
    enabled: false
    ## Specify the namespace in which the serviceMonitor resource will be created
    ##
    # namespace: ""
    ## Specify the interval at which metrics should be scraped
    ## For distributed setups with many replicas, consider the total scrape load on Prometheus.
    ## Example: 10 replicas * 30s interval = 10 targets scraped every 30 seconds
    ##
    interval: 30s
    ## Specify the timeout after which the scrape is ended
    ##
    # scrapeTimeout: 30s
    ## Specify Metric Relabellings to add to the scrape endpoint
    ## Useful for adding pod/instance labels in distributed setups
    ##
    # relabellings:
    ## Specify honorLabels parameter to add the scrape endpoint
    ##
    honorLabels: false
    ## Used to pass Labels that are used by the Prometheus installed in your cluster to select Service Monitors to work with
    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
    ## IMPORTANT: Set this to match your Prometheus Operator's serviceMonitorSelector
    ## Common examples:
    ##   additionalLabels:
    ##     release: prometheus           # For prometheus-operator/kube-prometheus-stack
    ##     prometheus: kube-prometheus   # For some custom setups
    ##
    additionalLabels: {}
    ## Set custom annotations.
    annotations: {}

nodeSelector: {}

tolerations: []

affinity: {}

## ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-dns-config
dnsPolicy: ""
dnsConfig: {}

# ============================================
# ENVIRONMENT VARIABLES
# ============================================

# Additional environment variables to be passed to Centrifugo container.
# Use for non-sensitive configuration that overrides config file options.
env: {}
  # CENTRIFUGO_LOG_LEVEL: "debug"

# Secret environment variables - reference external Kubernetes secrets.
# Use for sensitive configuration (tokens, passwords, API keys, etc.).
# The chart does NOT create secrets - you manage them externally.
envSecret: []
  # - name: CENTRIFUGO_CLIENT_TOKEN_HMAC_SECRET_KEY
  #   secretKeyRef:
  #     name: centrifugo-secrets
  #     key: client.token.hmac_secret_key
  # - name: CENTRIFUGO_ADMIN_PASSWORD
  #   secretKeyRef:
  #     name: centrifugo-secrets
  #     key: admin.password
  # - name: CENTRIFUGO_ADMIN_SECRET
  #   secretKeyRef:
  #     name: centrifugo-secrets
  #     key: admin.secret
  # - name: CENTRIFUGO_HTTP_API_KEY
  #   secretKeyRef:
  #     name: centrifugo-secrets
  #     key: http_api.key
  # - name: CENTRIFUGO_GRPC_API_KEY
  #   secretKeyRef:
  #     name: centrifugo-secrets
  #     key: grpc_api.key
  # - name: CENTRIFUGO_LICENSE
  #   secretKeyRef:
  #     name: centrifugo-secrets
  #     key: license

# Populate environment variables from ConfigMaps or Secrets.
# Use for bulk importing environment variables from external sources.
# The chart does NOT create these ConfigMaps/Secrets - you manage them externally.
envFrom: []
  # - configMapRef:
  #     name: centrifugo-config
  # - secretRef:
  #     name: centrifugo-secrets

# ============================================
# CENTRIFUGO CONFIGURATION
# ============================================

# Centrifugo configuration, will be transformed into config.json file.
# See https://centrifugal.dev/docs/server/configuration for all options.
config:
  # Engine to use. Default memory engine allows running only one Centrifugo pod.
  # Scale to many pods with Redis engine or Nats broker. Refer to Centrifugo
  # documentation: https://centrifugal.dev/docs/server/engines
  engine:
    type: "memory"

  # Enable admin web interface by default.
  admin:
    enabled: true

  # Array of namespaces.
  channel:
    namespaces: []

# ============================================
# VOLUMES
# ============================================

# Additional volumes for Centrifugo deployment.
volumes: []
  # - name: volume
  #   secret:
  #     secretName: volumeSecretName

# Additional volume mounts for Centrifugo container.
volumeMounts: []
  # - name: volume
  #   mountPath: "/volume"
  #   readOnly: true


# TopologySpreadConstraints for spreading pods across nodes.
# See https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
topologySpreadConstraints: []
  # - maxSkew: 1
  #   topologyKey: kubernetes.io/hostname
  #   whenUnsatisfiable: DoNotSchedule
  #   labelSelector:
  #     matchLabels:
  #       app.kubernetes.io/name: centrifugo

# Init Containers, e.g. for waiting for other resources like redis (evaluated as template).
# See https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
initContainers: []

# ============================================
# HOST CHECK JOB
# ============================================

# Configuration for the hostCheck pre-installation/pre-upgrade job.
# This job is used to validate DNS resolution for a specific remote host
# using both default and custom DNS servers (if provided).
# It can help ensure that external dependencies or services
# are accessible before proceeding with the deployment.
hostCheck:
  enabled: false
  # Docker image used for the host check job
  # Ensure this image has the necessary tools (e.g., dig) to perform DNS checks, for ex. registry.k8s.io/e2e-test-images/agnhost:2.39
  image: ""
  # Custom DNS server to use for host resolution (e.g., 8.8.8.8 for Google DNS)
  # If not provided, only the default DNS server will be used
  customDns: ""
  # The remote host that the DNS resolution check will target
  # Replace this with the hostname you want to validate
  remoteHost: ""
  # Define or override annotations
  # Examples:
  # "helm.sh/hook": pre-install,pre-upgrade
  # "helm.sh/hook-weight": "-1"
  # "helm.sh/hook-delete-policy": before-hook-creation
  annotations: {}
  # Resources configuration for the host check job's pod
  # You can specify CPU, memory requests, and limits here
  resources: {}
